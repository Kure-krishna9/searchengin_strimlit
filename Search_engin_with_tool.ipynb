{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a79623",
   "metadata": {},
   "source": [
    "## Toorls :\n",
    " \n",
    " Tools are enterface that an agent ,chain or LLm can use to interface with the word.\n",
    "\n",
    " tools like:\n",
    " ARXIV\n",
    " Wikipedia\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4000028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain (from -r requrements.txt (line 1))\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: ipykernel in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 2)) (6.30.1)\n",
      "Requirement already satisfied: python-dotenv in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 3)) (1.1.1)\n",
      "Collecting langchain_community (from -r requrements.txt (line 4))\n",
      "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pypdf in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 5)) (6.0.0)\n",
      "Requirement already satisfied: bs4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 6)) (0.0.2)\n",
      "Requirement already satisfied: arxiv in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: pymupdf in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: wikipedia in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 9)) (1.4.0)\n",
      "Collecting langchain-text-splitters (from -r requrements.txt (line 10))\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langchain-openai (from -r requrements.txt (line 11))\n",
      "  Using cached langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting chromadb (from -r requrements.txt (line 12))\n",
      "  Using cached chromadb-1.0.20-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting sentence_transformers (from -r requrements.txt (line 13))\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain_huggingface (from -r requrements.txt (line 14))\n",
      "  Using cached langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: faiss-cpu in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 15)) (1.12.0)\n",
      "Collecting langchain_chroma (from -r requrements.txt (line 17))\n",
      "  Using cached langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting streamlit (from -r requrements.txt (line 18))\n",
      "  Using cached streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting langchain-ollama (from -r requrements.txt (line 19))\n",
      "  Using cached langchain_ollama-0.3.7-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langchain_groq (from -r requrements.txt (line 20))\n",
      "  Using cached langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain_core (from -r requrements.txt (line 21))\n",
      "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langserve (from -r requrements.txt (line 22))\n",
      "  Using cached langserve-0.3.1-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: fastapi in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 23)) (0.116.1)\n",
      "Requirement already satisfied: sse_starlette in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 24)) (3.0.2)\n",
      "Requirement already satisfied: dotenv in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from -r requrements.txt (line 25)) (0.9.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain->-r requrements.txt (line 1)) (0.4.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain->-r requrements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain->-r requrements.txt (line 1)) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain->-r requrements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain->-r requrements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_core->-r requrements.txt (line 21)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_core->-r requrements.txt (line 21)) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_core->-r requrements.txt (line 21)) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_core->-r requrements.txt (line 21)) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r requrements.txt (line 21)) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requrements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requrements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requrements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requrements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requrements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requrements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requrements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requrements.txt (line 1)) (3.2.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (9.5.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipykernel->-r requrements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_community->-r requrements.txt (line 4)) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_community->-r requrements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_community->-r requrements.txt (line 4)) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_community->-r requrements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_community->-r requrements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community->-r requrements.txt (line 4)) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community->-r requrements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community->-r requrements.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community->-r requrements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from bs4->-r requrements.txt (line 6)) (4.13.5)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from arxiv->-r requrements.txt (line 7)) (6.0.12)\n",
      "Requirement already satisfied: sgmllib3k in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from feedparser~=6.0.10->arxiv->-r requrements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain-openai->-r requrements.txt (line 11)) (1.107.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain-openai->-r requrements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai->-r requrements.txt (line 11)) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai->-r requrements.txt (line 11)) (2025.9.1)\n",
      "Requirement already satisfied: build>=1.0.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requrements.txt (line 12)) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (1.36.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requrements.txt (line 12))\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requrements.txt (line 12))\n",
      "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (0.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (0.17.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (3.11.3)\n",
      "Requirement already satisfied: rich>=10.11.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from chromadb->-r requrements.txt (line 12)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requrements.txt (line 12)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requrements.txt (line 12)) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requrements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sentence_transformers->-r requrements.txt (line 13)) (4.56.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sentence_transformers->-r requrements.txt (line 13)) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sentence_transformers->-r requrements.txt (line 13)) (1.7.2)\n",
      "Requirement already satisfied: scipy in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sentence_transformers->-r requrements.txt (line 13)) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sentence_transformers->-r requrements.txt (line 13)) (0.34.4)\n",
      "Requirement already satisfied: Pillow in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sentence_transformers->-r requrements.txt (line 13)) (11.3.0)\n",
      "Requirement already satisfied: filelock in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requrements.txt (line 13)) (3.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requrements.txt (line 13)) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requrements.txt (line 13)) (2025.9.0)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit->-r requrements.txt (line 18))\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (8.2.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (2.3.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (6.32.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (21.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from streamlit->-r requrements.txt (line 18)) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requrements.txt (line 18)) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requrements.txt (line 18)) (2.4.0)\n",
      "Requirement already satisfied: colorama in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit->-r requrements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requrements.txt (line 18)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requrements.txt (line 18)) (5.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit->-r requrements.txt (line 18)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit->-r requrements.txt (line 18)) (2025.2)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain-ollama->-r requrements.txt (line 19)) (0.5.3)\n",
      "Requirement already satisfied: groq<1,>=0.30.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langchain_groq->-r requrements.txt (line 20)) (0.31.1)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from fastapi->-r requrements.txt (line 23)) (0.47.3)\n",
      "Requirement already satisfied: pyproject_hooks in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requrements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: decorator in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r requrements.txt (line 18)) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requrements.txt (line 12)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requrements.txt (line 12)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requrements.txt (line 12)) (0.27.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requrements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requrements.txt (line 2)) (311)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (0.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requrements.txt (line 12)) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requrements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requrements.txt (line 1)) (0.24.0)\n",
      "Requirement already satisfied: coloredlogs in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requrements.txt (line 12)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requrements.txt (line 12)) (25.2.10)\n",
      "Requirement already satisfied: sympy in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requrements.txt (line 12)) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requrements.txt (line 12)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requrements.txt (line 12)) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requrements.txt (line 12)) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requrements.txt (line 12)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requrements.txt (line 12)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requrements.txt (line 12)) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requrements.txt (line 12)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requrements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: networkx in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers->-r requrements.txt (line 13)) (3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requrements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requrements.txt (line 12)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requrements.txt (line 12)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requrements.txt (line 12)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requrements.txt (line 12)) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from beautifulsoup4->bs4->-r requrements.txt (line 6)) (2.8)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requrements.txt (line 12)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requrements.txt (line 12)) (3.5.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from scikit-learn->sentence_transformers->-r requrements.txt (line 13)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from scikit-learn->sentence_transformers->-r requrements.txt (line 13)) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in f:\\study material\\nlp_rag _projects\\langchain_searchengin_with_tools_agent\\.venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requrements.txt (line 2)) (0.2.3)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Using cached langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Using cached langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Using cached chromadb-1.0.20-cp39-abi3-win_amd64.whl (19.8 MB)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Using cached langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Using cached langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
      "Using cached streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached langchain_ollama-0.3.7-py3-none-any.whl (24 kB)\n",
      "Using cached langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
      "Using cached langserve-0.3.1-py3-none-any.whl (1.2 MB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "Installing collected packages: opentelemetry-sdk, langchain_core, altair, streamlit, sentence_transformers, opentelemetry-exporter-otlp-proto-grpc, langserve, langchain-text-splitters, langchain-openai, langchain-ollama, langchain_huggingface, langchain_groq, langchain, chromadb, langchain_community, langchain_chroma\n",
      "\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   ----------------------------------------  0/16 [opentelemetry-sdk]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   -- -------------------------------------  1/16 [langchain_core]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ----- ----------------------------------  2/16 [altair]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ------- --------------------------------  3/16 [streamlit]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   ---------- -----------------------------  4/16 [sentence_transformers]\n",
      "   --------- -------------------  5/16 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   --------------- ------------------------  6/16 [langserve]\n",
      "   --------------- ------------------------  6/16 [langserve]\n",
      "   --------------- ------------------------  6/16 [langserve]\n",
      "   --------------- ------------------------  6/16 [langserve]\n",
      "   --------------- ------------------------  6/16 [langserve]\n",
      "   ----------------- ----------------------  7/16 [langchain-text-splitters]\n",
      "   ----------------- ----------------------  7/16 [langchain-text-splitters]\n",
      "   ----------------- ----------------------  7/16 [langchain-text-splitters]\n",
      "   ----------------- ----------------------  7/16 [langchain-text-splitters]\n",
      "   ----------------- ----------------------  7/16 [langchain-text-splitters]\n",
      "   ----------------- ----------------------  7/16 [langchain-text-splitters]\n",
      "   -------------------- -------------------  8/16 [langchain-openai]\n",
      "   -------------------- -------------------  8/16 [langchain-openai]\n",
      "   -------------------- -------------------  8/16 [langchain-openai]\n",
      "   -------------------- -------------------  8/16 [langchain-openai]\n",
      "   ---------------------- -----------------  9/16 [langchain-ollama]\n",
      "   ---------------------- -----------------  9/16 [langchain-ollama]\n",
      "   ------------------------- -------------- 10/16 [langchain_huggingface]\n",
      "   ------------------------- -------------- 10/16 [langchain_huggingface]\n",
      "   ------------------------- -------------- 10/16 [langchain_huggingface]\n",
      "   --------------------------- ------------ 11/16 [langchain_groq]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   ------------------------------ --------- 12/16 [langchain]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   -------------------------------- ------- 13/16 [chromadb]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ----------------------------------- ---- 14/16 [langchain_community]\n",
      "   ------------------------------------- -- 15/16 [langchain_chroma]\n",
      "   ------------------------------------- -- 15/16 [langchain_chroma]\n",
      "   ---------------------------------------- 16/16 [langchain_chroma]\n",
      "\n",
      "Successfully installed altair-5.5.0 chromadb-1.0.20 langchain-0.3.27 langchain-ollama-0.3.7 langchain-openai-0.3.33 langchain-text-splitters-0.3.11 langchain_chroma-0.2.5 langchain_community-0.3.29 langchain_core-0.3.76 langchain_groq-0.3.8 langchain_huggingface-0.3.1 langserve-0.3.1 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-sdk-1.36.0 sentence_transformers-5.1.0 streamlit-1.49.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requrements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7443d",
   "metadata": {},
   "source": [
    "### TOOLS CReation:\n",
    "#### Search ENgine with tools and agents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b376e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv--Research\n",
    "## Tools Creation\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609ea098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the inbuild tools of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917c7bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "Arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(Arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eab6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,Arxiv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d43492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Custom Tool[RAG Tool]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6c33134",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_token\"]=os.getenv(\"HF_token\")\n",
    "os.environ[\"Groq_key\"]=os.getenv(\"Groq_key\")\n",
    "os.environ[\"Langchain_api_key\"]=os.getenv(\"Langchain_api_key\")\n",
    "os.environ[\"Langchai_project\"]=\"Tool_agent_llm_project\"\n",
    "Embeddings=HuggingFaceEmbeddings(model='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d94d0615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E35E473E90>, search_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documet=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=400)\n",
    "split_doc=documet.split_documents(docs)\n",
    "vectore_store=FAISS.from_documents(split_doc,embedding=Embeddings)\n",
    "retriver=vectore_store.as_retriever()\n",
    "retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78a759de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsith-search'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriver_tool=create_retriever_tool(retriver,\"langsith-search\",\"Search any information about langsmith\")\n",
    "retriver_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c70620bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\study material\\\\NLP_Rag _Projects\\\\Langchain_searchengin_with_tools_agent\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langsith-search', description='Search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E35E54C180>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E35E473E90>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E35E54C220>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E35E473E90>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[wiki,Arxiv,retriver_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3775e0",
   "metadata": {},
   "source": [
    "#### Run All Tool with Agents and LLM\n",
    " ##### Tools,LLM ---AgentExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "920e5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.getenv(\"Groq_key\")\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model=\"llama-3.1-8b-instant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbfbba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt template\n",
    "\n",
    "from langchain import hub\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c66ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E339D7B9C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E339D7B9C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E3000AFFD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E30001B290>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsith-search', 'description': 'Search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agents\n",
    "from langchain.agents import create_openai_tools_agent,initialize_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4682aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E339D7B9C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E339D7B9C0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E3000AFFD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E30001B290>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsith-search', 'description': 'Search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\study material\\\\NLP_Rag _Projects\\\\Langchain_searchengin_with_tools_agent\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsith-search', description='Search any information about langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E35E54C180>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E35E473E90>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E35E54C220>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E35E473E90>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer=AgentExecutor(agent=agent, tools=tools,verbose=True)\n",
    "agent_executer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33896dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsith-search` with `{'query': 'langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith - Docs by LangChainDocs by LangChain home pagePythonSearch...KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQDocs by LangChain home pagePythonSearch...KAsk AIGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "LangSmith is framework agnostic you can use it with or without LangChains open source frameworks langchain and langgraph.\n",
      "\n",
      "Start tracingGain visibility into each step your application takes when handling a request to debug faster.Learn moreEvaluate your applicationMeasure quality of your applications over time to build more reliable AI applications.Learn moreTest your promptsIterate on prompts, with automatic version control and collaboration features.Learn moreSet up your workspaceSet up your workspace, configure admin settings, and invite your team to collaborate.Learn moreWas this page helpful?YesNoTrace an applicationAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'LangSmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\u001b[32;1m\u001b[1;3mThe LangSmith platform is a subset of the larger LangChain framework.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about langsmith',\n",
       " 'output': 'The LangSmith platform is a subset of the larger LangChain framework.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Tell me about langsmith\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
